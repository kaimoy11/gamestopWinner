{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#grab hidden values\n",
    "USERNAME_PRO = os.environ.get('USERNAME')\n",
    "PASSWORD_USER = os.environ.get('PASSWORD')\n",
    "CLIENT_REDD = os.environ.get('CLIENT')\n",
    "CLIENT_PASS = os.environ.get('CLIENTPASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.3: import this module and log in!\n",
    "import praw\n",
    "reddit = praw.Reddit(client_id= CLIENT_REDD, # App ID\n",
    "                     client_secret= CLIENT_PASS, # App password\n",
    "                     user_agent='My Test Reddit Scraper', # App name (can be different)\n",
    "                     username= USERNAME_PRO, # Username\n",
    "                     password= PASSWORD_USER) # User password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wallstreetbets\n",
      "wallstreetbets\n",
      "Our official Twitter: [@Official_WSB](https://twitter.com/official_wsb)\n",
      "\n",
      "---\n",
      "\n",
      "The rules and submission guidelines are maintained on new Reddit so be sure to check them and make sure you're up to date.\n",
      "\n",
      "* Read the [rules](https://www.reddit.com/r/wallstreetbets/about/rules)\n",
      "\n",
      "* Read the [comment and submission guide](https://www.reddit.com/r/wallstreetbets/wiki/contentguide)\n",
      "\n",
      "* Read the [FAQ](https://www.reddit.com/r/wallstreetbets/wiki/faq) if you're new to both wallstreetbets and trading.\n",
      "\n",
      "---\n",
      "**Join the discord**\n",
      "\n",
      "[WSB Discord](https://discord.gg/wallstreetbets)\n",
      "\n",
      "[Appeal a Discord ban](https://discord.gg/S9vH92cQ6W)\n",
      "\n",
      "\n",
      "**filter by flairs**\n",
      "\n",
      "^Navigate ^WSB |^We ^recommend ^best ^daily ^DD\n",
      ":--|:--     \n",
      "**DD** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ADD) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADD&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADD&restrict_sr=on&t=week)\n",
      "**Discussion** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ADiscussion) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADiscussion&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ADiscussion&restrict_sr=on&t=week)\n",
      "**YOLO** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AYOLO) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AYOLO&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AYOLO&restrict_sr=on&t=week)\n",
      "**Gain** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AGain) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AGain&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AGain&restrict_sr=on&t=week)\n",
      "**Loss** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ALoss) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ALoss&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ALoss&restrict_sr=on&t=week)\n",
      "**Shitpost** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AShitpost) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AShitpost&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AShitpost&restrict_sr=on&t=week)\n",
      "**Meme** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AMeme) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AMeme&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AMeme&restrict_sr=on&t=week)\n",
      "**Storytime** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AStorytime) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStorytime&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStorytime&restrict_sr=on&t=week)\n",
      "**Satire** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ASatire) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ASatire&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ASatire&restrict_sr=on&t=week)\n",
      "**Options** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AOptions) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AOptions&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AOptions&restrict_sr=on&t=week)\n",
      "**Futures** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AFutures) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFutures&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFutures&restrict_sr=on&t=week)\n",
      "**Forex** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AForex) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AForex&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AForex&restrict_sr=on&t=week)\n",
      "**Stocks** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AStocks) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStocks&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AStocks&restrict_sr=on&t=week)\n",
      "**Fundamentals** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3AFundamentals) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFundamentals&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3AFundamentals&restrict_sr=on&t=week)\n",
      "**Technicals** | [All](https://ns.reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3ATechnicals) / [**Best Daily**](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ATechnicals&restrict_sr=on&t=day) / [Best Weekly](https://ns.reddit.com/r/wallstreetbets/search?sort=top&q=flair%3ATechnicals&restrict_sr=on&t=week)\n",
      "\n",
      "\n",
      "[Earnings Thread](https://reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3A\"Earnings%20Thread\") - [Daily Thread](https://reddit.com/r/wallstreetbets/search?sort=new&restrict_sr=on&q=flair%3A\"Daily%20Discussion\")\n",
      "\n",
      "---\n",
      "\n",
      "**Market Trading Hours**\n",
      "\n",
      "|Exchange|Open|Close|\n",
      "|:-------:|--------:|--------:|\n",
      "|[Frankfurt](http://goo.gl/9teCjs) | 9:00 AM | 8:00 PM | \n",
      "|[New York](https://goo.gl/eODOhO) | 9:30 AM  | 4:00 PM|\n",
      "|[CME](http://goo.gl/VZZDPg) | 5:00 PM | 4:15 PM |\n",
      "|[CBOE](http://goo.gl/fMSNBY) | 8:30 AM | 3:15 PM  |\n",
      "|[Tokyo](http://goo.gl/Aiwygk) | 9:00 AM | 3:00 PM  |\n",
      "|[Hong Kong](http://goo.gl/vLR2vh) | 9:30 AM | 4:00 PM  |\n",
      "* Hours respective to their own timezone.\n",
      "\n",
      "[^^source](https://goo.gl/hk9CB4)\n"
     ]
    }
   ],
   "source": [
    "# To get a specific subreddit\n",
    "subreddit = reddit.subreddit('wallstreetbets')\n",
    "print(subreddit.display_name)  # Displayed name\n",
    "print(subreddit.title)         # \"Full\" name\n",
    "print(subreddit.description)   # Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kaimoy/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaderSentiment as vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7218\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "#run through dataset and store comment data inot lists\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "file_list = []\n",
    "comment_id_list = []\n",
    "comment_date_list=[]\n",
    "comment_body_list=[]\n",
    "\n",
    "#UNIX time for the minimum post date-December 15th, 2021\n",
    "submission_lower_date = 1608033086\n",
    "#UNIX time for the maximum post date-February 15th, 2021 \n",
    "submission_cap_date = 1613393219\n",
    "#search for keyword gamestop or gme \n",
    "for thread in subreddit.search(query=\"gamestop gme\".lower()):\n",
    "    if(thread.created_utc > submission_lower_date and thread.created_utc < submission_cap_date):\n",
    "            t = thread.created_utc\n",
    "            dt = datetime.fromtimestamp(t)\n",
    "            \n",
    "            file_list.append(thread)\n",
    "            comments = thread.comments.list()\n",
    "            for comment in comments:\n",
    "                try:\n",
    "                    comment_id_list.append(comment.id)\n",
    "                    comment_date_list.append(comment.created_utc)\n",
    "                    comment_body_list.append(comment.body)\n",
    "                    analyzer(comment)\n",
    "                   # print(comment.id)\n",
    "                    #print(comment.created_utc)\n",
    "                    #print(comment.body)\n",
    "                    #print()\n",
    "                except:\n",
    "                    pass\n",
    "print(len(comment_id_list))\n",
    "print(len(file_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run vader sentiment analysis for each comment body\n",
    "#store ONLY vader compound score into list vadercompound_list\n",
    "vs_list=[]\n",
    "sentiment_list=[]\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vadercompound_list = []\n",
    "for comment in comment_body_list:\n",
    "        vs = analyzer.polarity_scores(comment)\n",
    "        compound_score = vs[\"compound\"]\n",
    "        sentiment = \"\"\n",
    "        if(compound_score > 0.05):\n",
    "            sentiment = \"Positive\"\n",
    "        elif(compound_score < -0.05):\n",
    "            sentiment = \"Negative\"\n",
    "        else:\n",
    "            sentiment = \"Neutral\"\n",
    "        vs_list.append(vs)\n",
    "        sentiment_list.append(sentiment)\n",
    "        vadercompound_list.append(compound_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Body: They’ll be losing a lot of users \n",
      " Time: 1611852349.0 \n",
      "Score: -0.3818\n"
     ]
    }
   ],
   "source": [
    "#prints comment date, body, score\n",
    "print(\"Comment Body:\",comment_body_list[40], \"\\n\",\"Time:\", comment_date_list[40],\"\\nScore:\",vadercompound_list[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Body: They’ll be losing a lot of users \n",
      "\n",
      "Vader Scores: {'neg': 0.302, 'neu': 0.698, 'pos': 0.0, 'compound': -0.3818} \n",
      "\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "print(\"Comment Body:\",comment_body_list[40],\"\\n\")\n",
    "print(\"Vader Scores:\",str(vs_list[40]),\"\\n\")\n",
    "print(\"Sentiment:\",sentiment_list[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 day = 86400 seconds/unix\n",
    "day = 86400\n",
    "start_time=1608033086    #first observation day, specified above \n",
    "end_time =0\n",
    "final_time =1613393219 #last day of market observation\n",
    "duration = 63\n",
    "\n",
    "#list for positive vader scored comments total\n",
    "pos_comment=[]\n",
    "#list for positive vader scored comments total\n",
    "neg_comment=[]\n",
    "#list for positive vader scored comments total\n",
    "neut_comment=[]\n",
    "#total comments in duration\n",
    "total_comment=[]\n",
    "daily_avg_pos=[]\n",
    "daily_avg_neg=[]\n",
    "daily_avg_neut=[]\n",
    "\n",
    "#end time is always one day ahead of start time\n",
    "end_time = start_time + day\n",
    "for t in range(duration):\n",
    "    #list of total comments per day\n",
    "    daily_total=[]\n",
    "    #list of comment times that resets for each day \n",
    "    daily_pos=[]\n",
    "    daily_neg=[]\n",
    "    daily_neut=[]\n",
    "    scored_pos=0\n",
    "    scored_neg=0\n",
    "    scored_neut=0\n",
    "    for i in range(len(comment_date_list)):\n",
    "        if(comment_date_list[i] > start_time and comment_date_list[i] < end_time):\n",
    "            if(vadercompound_list[i] > 0.05):\n",
    "                daily_pos.append(comment_date_list[i])\n",
    "                scored_pos+=vadercompound_list[i]\n",
    "                #print(vadercompound_list[i])\n",
    "            elif(vadercompound_list[i] < -0.05):\n",
    "                daily_neg.append(comment_date_list[i])\n",
    "                scored_neg+=vadercompound_list[i]\n",
    "            else:\n",
    "                daily_neut.append(comment_date_list[i])\n",
    "                scored_neut+=vadercompound_list[i]\n",
    "                \n",
    "            daily_total.append(comment_date_list[i])\n",
    "    if((len(daily_pos))>0):\n",
    "        daily_avg_pos.append(scored_pos/(len(daily_pos)))\n",
    "    else:\n",
    "        daily_avg_pos.append(0)\n",
    "    if((len(daily_neg))>0):\n",
    "        daily_avg_neg.append(scored_neg/(len(daily_neg)))\n",
    "    else:\n",
    "        daily_avg_neg.append(0)\n",
    "    if((len(daily_neut))>0):\n",
    "        daily_avg_neut.append(scored_neut/(len(daily_neut)))\n",
    "    else:\n",
    "        daily_avg_neut.append(0)\n",
    "    \n",
    "    end_time += day\n",
    "    start_time +=day\n",
    "    pos_comment.append(len(daily_pos))\n",
    "    neg_comment.append(len(daily_neg))\n",
    "    neut_comment.append(len(daily_neut))\n",
    "    total_comment.append(len(daily_total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0.524394366197183, 0.5305285714285715, 0.4215, 0.5361361538461534, 0.5469872727272728, 0.5725258064516129, 0, 0, 0, 0.6048166666666667, 0.45149999999999996, 0, 0, 0.5952355555555556, 0.5803908163265304, 0.5418858823529411, 0.4833, 0.513257894736842, 0.29569999999999996, 0.8481, 0, 0, 0.5559725663716816, 0.5196026315789473, 0.5755791666666668, 0.46640714285714285, 0.44540588235294126, 0.5684333333333333, 0.689675, 0.5657732142857136, 0.54323, 0.5222853658536586, 0.5530391304347827, 0.58933, 0.35342, 0, 0.466, 0.5094591743119258, 0.49846153846153857, 0.583409090909091, 0.5386295566502458, 0.564871186440678, 0.5255833333333333, 0.5434177777777779, 0.32729230769230766, 0.5849769230769231, 0.35435, 0.638, 0.3355, 0.5282015789473685, 0.461525, 0.63915, 0.47529047619047615, 0.46727500000000005, 0.578252, 0.47961, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(daily_avg_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 140, 94, 5, 308, 124, 41, 1, 1, 0, 26, 13, 0, 0, 72, 244, 157, 55, 34, 6, 2, 0, 0, 190, 185, 51, 546, 68, 24, 6, 417, 39, 98, 88, 86, 7, 3, 14, 533, 172, 29, 470, 704, 587, 101, 44, 81, 12, 18, 7, 390, 6, 2, 58, 14, 117, 16, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "#lists the total frequency of comments per day\n",
    "print(total_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0888'], ['0.01'], ['0.0708'], ['0.0539'], ['0'], ['0'], ['-0.0064'], ['0.2531'], ['0.057'], ['-0.0204'], ['0'], ['0'], ['0'], ['0.0417'], ['-0.0767'], ['-0.0062'], ['-0.0218'], ['0'], ['0'], ['0'], ['-0.0844'], ['0.007'], ['0.057'], ['-0.0153'], ['-0.0216'], ['0'], ['0'], ['0.1272'], ['0.0005'], ['0.5739'], ['0.271'], ['-0.1105'], ['0'], ['0'], ['0'], ['0.1087'], ['-0.0061'], ['0.099'], ['0.5108'], ['0'], ['0'], ['0.1812'], ['0.9272'], ['1.3484'], ['-0.4429'], ['0.6787'], ['0'], ['0'], ['-0.3077'], ['-0.6'], ['0.0268'], ['-0.4211'], ['0.192'], ['0'], ['0'], ['-0.0591'], ['-0.1615'], ['0.0177'], ['-0.002'], ['0.0254'], ['0'], ['0'], ['0']]\n"
     ]
    }
   ],
   "source": [
    "ground_truth=[]\n",
    "\n",
    "with open(r\"gmeChange - Sheet1.csv\",newline ='') as csvfile:\n",
    "    csvReader = csv.reader(csvfile)\n",
    "    for row in csvReader:\n",
    "        ground_truth.append(row)\n",
    "\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = pd.DataFrame(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arr = np.asarray(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneD_truth = df_arr.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_truth =np.array(oneD_truth,dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0   0.0888\n",
       "1     0.01\n",
       "2   0.0708\n",
       "3   0.0539\n",
       "4        0\n",
       "..     ...\n",
       "58  -0.002\n",
       "59  0.0254\n",
       "60       0\n",
       "61       0\n",
       "62       0\n",
       "\n",
       "[63 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create linear regression model \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double brackets turns it from array into matrix\n",
    "X = []\n",
    "#x0=[[]]\n",
    "#x1=[[]]\n",
    "#x2=[[]]\n",
    "\n",
    "#x0 = np.asarray(x0) # do for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "constant = []\n",
    "for i in range(len(oneD_truth)):\n",
    "    constant.append(0.08205121951)\n",
    "print(len(constant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.8800e-02  1.0000e-02  7.0800e-02  5.3900e-02  0.0000e+00  0.0000e+00\n",
      " -6.4000e-03  2.5310e-01  5.7000e-02 -2.0400e-02  0.0000e+00  0.0000e+00\n",
      "  0.0000e+00  4.1700e-02 -7.6700e-02 -6.2000e-03 -2.1800e-02  0.0000e+00\n",
      "  0.0000e+00  0.0000e+00 -8.4400e-02  7.0000e-03  5.7000e-02 -1.5300e-02\n",
      " -2.1600e-02  0.0000e+00  0.0000e+00  1.2720e-01  5.0000e-04  5.7390e-01\n",
      "  2.7100e-01 -1.1050e-01  0.0000e+00  0.0000e+00  0.0000e+00  1.0870e-01\n",
      " -6.1000e-03  9.9000e-02  5.1080e-01  0.0000e+00  0.0000e+00  1.8120e-01\n",
      "  9.2720e-01  1.3484e+00 -4.4290e-01  6.7870e-01  0.0000e+00  0.0000e+00\n",
      " -3.0770e-01 -6.0000e-01  2.6800e-02 -4.2110e-01  1.9200e-01  0.0000e+00\n",
      "  0.0000e+00 -5.9100e-02 -1.6150e-01  1.7700e-02 -2.0000e-03  2.5400e-02\n",
      "  0.0000e+00  0.0000e+00  0.0000e+00]\n",
      "[[0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122 0.08205122 0.08205122 0.08205122\n",
      "  0.08205122 0.08205122 0.08205122]]\n",
      "[[  0   0   0   0   0  71  35   1 130  55  31   0   0   0  12   4   0   0\n",
      "   45  98  85  29  19   2   1   0   0 113  76  24 196  34   9   4 224  20\n",
      "   41  46  50   5   0   7 218  65  11 203 295 246  45  13  39   6   8   2\n",
      "  190   4   2  21   4  50  10   0   0]]\n",
      "[[  0   0   0   0   0  17  18   1  71  31   6   1   1   0   7   3   0   0\n",
      "   13  52  22   9   5   2   1   0   0  34  30   7 119  14   8   0  78   8\n",
      "   24  14  14   2   2   3 112  36   7 102 161 163  19  13  17   3   2   3\n",
      "  126   1   0  21   4  23   3   1   0]]\n",
      "[[0.         0.         0.         0.         0.         0.52439437\n",
      "  0.53052857 0.4215     0.53613615 0.54698727 0.57252581 0.\n",
      "  0.         0.         0.60481667 0.4515     0.         0.\n",
      "  0.59523556 0.58039082 0.54188588 0.4833     0.51325789 0.2957\n",
      "  0.8481     0.         0.         0.55597257 0.51960263 0.57557917\n",
      "  0.46640714 0.44540588 0.56843333 0.689675   0.56577321 0.54323\n",
      "  0.52228537 0.55303913 0.58933    0.35342    0.         0.466\n",
      "  0.50945917 0.49846154 0.58340909 0.53862956 0.56487119 0.52558333\n",
      "  0.54341778 0.32729231 0.58497692 0.35435    0.638      0.3355\n",
      "  0.52820158 0.461525   0.63915    0.47529048 0.467275   0.578252\n",
      "  0.47961    0.         0.        ]]\n",
      "[[ 0.          0.          0.          0.          0.         -0.46582941\n",
      "  -0.44988333 -0.5423     -0.50133662 -0.48213871 -0.35841667 -0.296\n",
      "  -0.1531      0.         -0.46062857 -0.22753333  0.          0.\n",
      "  -0.43895385 -0.43326538 -0.49136818 -0.3937     -0.48286    -0.7964\n",
      "  -0.4199      0.          0.         -0.43425882 -0.44531    -0.44197143\n",
      "  -0.45093193 -0.44995714 -0.5018875   0.         -0.45575897 -0.6545875\n",
      "  -0.50352083 -0.49597143 -0.50653571 -0.6878     -0.18795    -0.3708\n",
      "  -0.49194554 -0.46391111 -0.41455714 -0.47647157 -0.45909068 -0.50186258\n",
      "  -0.50013684 -0.42100769 -0.42211176 -0.3409     -0.64225    -0.31283333\n",
      "  -0.53593016 -0.296       0.         -0.3446     -0.480975   -0.51143913\n",
      "  -0.2953     -0.3875      0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Y = float_truth\n",
    "Y = np.asarray(Y)\n",
    "#Constant Variable\n",
    "x0 = [constant]\n",
    "#Count of Positive Comments on a given day \n",
    "x1 = [pos_comment]\n",
    "#Count of Negative Comments\n",
    "x2 = [neg_comment]\n",
    "x3 = [daily_avg_pos]\n",
    "x4 = [daily_avg_neg]\n",
    "x0 = np.asarray(x0)\n",
    "x1 = np.asarray(x1)\n",
    "x2 = np.asarray(x2)\n",
    "x3 = np.asarray(x3)\n",
    "x4 = np.asarray(x4)\n",
    "print(Y)\n",
    "print(x0)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "print(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  7.10000000e+01  1.70000000e+01  5.24394366e-01\n",
      "  -4.65829412e-01]\n",
      " [ 8.20512195e-02  3.50000000e+01  1.80000000e+01  5.30528571e-01\n",
      "  -4.49883333e-01]\n",
      " [ 8.20512195e-02  1.00000000e+00  1.00000000e+00  4.21500000e-01\n",
      "  -5.42300000e-01]\n",
      " [ 8.20512195e-02  1.30000000e+02  7.10000000e+01  5.36136154e-01\n",
      "  -5.01336620e-01]\n",
      " [ 8.20512195e-02  5.50000000e+01  3.10000000e+01  5.46987273e-01\n",
      "  -4.82138710e-01]\n",
      " [ 8.20512195e-02  3.10000000e+01  6.00000000e+00  5.72525806e-01\n",
      "  -3.58416667e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -2.96000000e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -1.53100000e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  1.20000000e+01  7.00000000e+00  6.04816667e-01\n",
      "  -4.60628571e-01]\n",
      " [ 8.20512195e-02  4.00000000e+00  3.00000000e+00  4.51500000e-01\n",
      "  -2.27533333e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  4.50000000e+01  1.30000000e+01  5.95235556e-01\n",
      "  -4.38953846e-01]\n",
      " [ 8.20512195e-02  9.80000000e+01  5.20000000e+01  5.80390816e-01\n",
      "  -4.33265385e-01]\n",
      " [ 8.20512195e-02  8.50000000e+01  2.20000000e+01  5.41885882e-01\n",
      "  -4.91368182e-01]\n",
      " [ 8.20512195e-02  2.90000000e+01  9.00000000e+00  4.83300000e-01\n",
      "  -3.93700000e-01]\n",
      " [ 8.20512195e-02  1.90000000e+01  5.00000000e+00  5.13257895e-01\n",
      "  -4.82860000e-01]\n",
      " [ 8.20512195e-02  2.00000000e+00  2.00000000e+00  2.95700000e-01\n",
      "  -7.96400000e-01]\n",
      " [ 8.20512195e-02  1.00000000e+00  1.00000000e+00  8.48100000e-01\n",
      "  -4.19900000e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  1.13000000e+02  3.40000000e+01  5.55972566e-01\n",
      "  -4.34258824e-01]\n",
      " [ 8.20512195e-02  7.60000000e+01  3.00000000e+01  5.19602632e-01\n",
      "  -4.45310000e-01]\n",
      " [ 8.20512195e-02  2.40000000e+01  7.00000000e+00  5.75579167e-01\n",
      "  -4.41971429e-01]\n",
      " [ 8.20512195e-02  1.96000000e+02  1.19000000e+02  4.66407143e-01\n",
      "  -4.50931933e-01]\n",
      " [ 8.20512195e-02  3.40000000e+01  1.40000000e+01  4.45405882e-01\n",
      "  -4.49957143e-01]\n",
      " [ 8.20512195e-02  9.00000000e+00  8.00000000e+00  5.68433333e-01\n",
      "  -5.01887500e-01]\n",
      " [ 8.20512195e-02  4.00000000e+00  0.00000000e+00  6.89675000e-01\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  2.24000000e+02  7.80000000e+01  5.65773214e-01\n",
      "  -4.55758974e-01]\n",
      " [ 8.20512195e-02  2.00000000e+01  8.00000000e+00  5.43230000e-01\n",
      "  -6.54587500e-01]\n",
      " [ 8.20512195e-02  4.10000000e+01  2.40000000e+01  5.22285366e-01\n",
      "  -5.03520833e-01]\n",
      " [ 8.20512195e-02  4.60000000e+01  1.40000000e+01  5.53039130e-01\n",
      "  -4.95971429e-01]\n",
      " [ 8.20512195e-02  5.00000000e+01  1.40000000e+01  5.89330000e-01\n",
      "  -5.06535714e-01]\n",
      " [ 8.20512195e-02  5.00000000e+00  2.00000000e+00  3.53420000e-01\n",
      "  -6.87800000e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  2.00000000e+00  0.00000000e+00\n",
      "  -1.87950000e-01]\n",
      " [ 8.20512195e-02  7.00000000e+00  3.00000000e+00  4.66000000e-01\n",
      "  -3.70800000e-01]\n",
      " [ 8.20512195e-02  2.18000000e+02  1.12000000e+02  5.09459174e-01\n",
      "  -4.91945536e-01]\n",
      " [ 8.20512195e-02  6.50000000e+01  3.60000000e+01  4.98461538e-01\n",
      "  -4.63911111e-01]\n",
      " [ 8.20512195e-02  1.10000000e+01  7.00000000e+00  5.83409091e-01\n",
      "  -4.14557143e-01]\n",
      " [ 8.20512195e-02  2.03000000e+02  1.02000000e+02  5.38629557e-01\n",
      "  -4.76471569e-01]\n",
      " [ 8.20512195e-02  2.95000000e+02  1.61000000e+02  5.64871186e-01\n",
      "  -4.59090683e-01]\n",
      " [ 8.20512195e-02  2.46000000e+02  1.63000000e+02  5.25583333e-01\n",
      "  -5.01862577e-01]\n",
      " [ 8.20512195e-02  4.50000000e+01  1.90000000e+01  5.43417778e-01\n",
      "  -5.00136842e-01]\n",
      " [ 8.20512195e-02  1.30000000e+01  1.30000000e+01  3.27292308e-01\n",
      "  -4.21007692e-01]\n",
      " [ 8.20512195e-02  3.90000000e+01  1.70000000e+01  5.84976923e-01\n",
      "  -4.22111765e-01]\n",
      " [ 8.20512195e-02  6.00000000e+00  3.00000000e+00  3.54350000e-01\n",
      "  -3.40900000e-01]\n",
      " [ 8.20512195e-02  8.00000000e+00  2.00000000e+00  6.38000000e-01\n",
      "  -6.42250000e-01]\n",
      " [ 8.20512195e-02  2.00000000e+00  3.00000000e+00  3.35500000e-01\n",
      "  -3.12833333e-01]\n",
      " [ 8.20512195e-02  1.90000000e+02  1.26000000e+02  5.28201579e-01\n",
      "  -5.35930159e-01]\n",
      " [ 8.20512195e-02  4.00000000e+00  1.00000000e+00  4.61525000e-01\n",
      "  -2.96000000e-01]\n",
      " [ 8.20512195e-02  2.00000000e+00  0.00000000e+00  6.39150000e-01\n",
      "   0.00000000e+00]\n",
      " [ 8.20512195e-02  2.10000000e+01  2.10000000e+01  4.75290476e-01\n",
      "  -3.44600000e-01]\n",
      " [ 8.20512195e-02  4.00000000e+00  4.00000000e+00  4.67275000e-01\n",
      "  -4.80975000e-01]\n",
      " [ 8.20512195e-02  5.00000000e+01  2.30000000e+01  5.78252000e-01\n",
      "  -5.11439130e-01]\n",
      " [ 8.20512195e-02  1.00000000e+01  3.00000000e+00  4.79610000e-01\n",
      "  -2.95300000e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  -3.87500000e-01]\n",
      " [ 8.20512195e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((x0.T,x1.T,x2.T,x3.T,x4.T),axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09562173399397855\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X,Y)\n",
    "print(reg.score(X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0888' '0.01' '0.0708' '0.0539' '0' '0' '-0.0064' '0.2531' '0.057'\n",
      " '-0.0204' '0' '0' '0' '0.0417' '-0.0767' '-0.0062' '-0.0218' '0' '0' '0'\n",
      " '-0.0844' '0.007' '0.057' '-0.0153' '-0.0216' '0' '0' '0.1272' '0.0005'\n",
      " '0.5739' '0.271' '-0.1105' '0' '0' '0' '0.1087' '-0.0061' '0.099'\n",
      " '0.5108' '0' '0' '0.1812' '0.9272' '1.3484' '-0.4429' '0.6787' '0' '0'\n",
      " '-0.3077' '-0.6' '0.0268' '-0.4211' '0.192' '0' '0' '-0.0591' '-0.1615'\n",
      " '0.0177' '-0.002' '0.0254' '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.096\n",
      "Model:                            OLS   Adj. R-squared:                  0.033\n",
      "Method:                 Least Squares   F-statistic:                     1.533\n",
      "Date:                Mon, 03 Oct 2022   Prob (F-statistic):              0.205\n",
      "Time:                        11:05:31   Log-Likelihood:                -4.4980\n",
      "No. Observations:                  63   AIC:                             19.00\n",
      "Df Residuals:                      58   BIC:                             29.71\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0988      0.876     -0.113      0.911      -1.853       1.655\n",
      "x2             0.0023      0.002      1.144      0.257      -0.002       0.006\n",
      "x3            -0.0022      0.004     -0.613      0.542      -0.009       0.005\n",
      "x4            -0.0797      0.202     -0.395      0.694      -0.483       0.324\n",
      "x5            -0.1058      0.228     -0.464      0.644      -0.562       0.350\n",
      "==============================================================================\n",
      "Omnibus:                       46.073   Durbin-Watson:                   1.833\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              226.065\n",
      "Skew:                           1.963   Prob(JB):                     8.14e-50\n",
      "Kurtosis:                      11.409   Cond. No.                     2.46e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.46e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "ols = sm.OLS(Y,X)  \n",
    "#endog = 1d response variable\n",
    "ols_result = ols.fit()\n",
    "print(ols_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
